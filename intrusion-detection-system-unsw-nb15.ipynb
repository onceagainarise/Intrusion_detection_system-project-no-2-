{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Importing libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"ImportError","evalue":"cannot import name 'plot_roc_curve' from 'sklearn.metrics' (c:\\Users\\arise\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, auc\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score, roc_curve\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_recall_curve, PrecisionRecallDisplay, roc_auc_score, plot_roc_curve\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n","\u001b[1;31mImportError\u001b[0m: cannot import name 'plot_roc_curve' from 'sklearn.metrics' (c:\\Users\\arise\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)"]}],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import time\n","import matplotlib.pyplot as plt\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, auc\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve\n","from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, roc_auc_score, plot_roc_curve\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_selection import RFE\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB"]},{"cell_type":"markdown","metadata":{},"source":["# Loading and Checking the dataset"]},{"cell_type":"markdown","metadata":{},"source":["We chose UNSW_NB15 dataset for this IDS project.\n","\n","This is the link for [UNSW_NB15 dataset](https://www.kaggle.com/datasets/mrwellsdavid/unsw-nb15).\n","\n","The training and testing sets were reversed, so we changed the names before loading them from CSV files."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["df_train = pd.read_csv(\"./UNSW_NB15/UNSW_NB15_training-set.csv\")\n","df_test = pd.read_csv(\"./UNSW_NB15/UNSW_NB15_testing-set.csv\")\n","print(\"Length of training set: \", len(df_train))\n","print(\"Length of testing set: \", len(df_test))"]},{"cell_type":"markdown","metadata":{},"source":["In order to ensure the balance between the training and testing sets and avoid processing twice, we decided to concatenate them into one dataframe and redivide them with a different ratio later with *sklearn.model_selection.train_test_split()*."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["df = pd.concat([df_train, df_test])\n","# information about the dataset\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.describe(include=\"all\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Checking for duplicates"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(df.duplicated().sum())"]},{"cell_type":"markdown","metadata":{},"source":["There is no duplicate record."]},{"cell_type":"markdown","metadata":{},"source":["## Checking for missing values"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["print(df.isna().sum())"]},{"cell_type":"markdown","metadata":{},"source":["There is no missing value."]},{"cell_type":"markdown","metadata":{},"source":["## Checking the balance between benign and attack data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['label'].value_counts().plot.bar()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['label'].value_counts(normalize=True)"]},{"cell_type":"markdown","metadata":{},"source":["The ratio between attack and normal data is not equal, but just slightly imbalanced.\n","Therefore, we will not do a sampling fix here."]},{"cell_type":"markdown","metadata":{},"source":["# Feature engineering"]},{"cell_type":"markdown","metadata":{},"source":["## Dropping unnecessary features\n","The first column we will drop is <code>id</code>. This is just for identification, so we can remove this column.\n","\n","This is a binary classification problem, so we only use column <code>label</code> to classify <code>attack</code> (1) or <code>normal</code> (0).\n","Then, we do not need attack details in <code>attack_cat</code>."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = df.drop(columns=['id', 'attack_cat'])"]},{"cell_type":"markdown","metadata":{},"source":["## Encoding categorical features\n","Encoding categorical features using LabelEncoder."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_cat = df.select_dtypes(exclude=[np.number])\n","print(df_cat.columns)\n","for feature in df_cat.columns:\n","    df[feature] = LabelEncoder().fit_transform(df[feature])"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Data Correlation\n","Removing highly correlated features."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sns.heatmap(df.corr())\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["columns = df.columns.tolist()\n","corr = df.corr()\n","correlated_vars = []\n","for i in range(len(columns) - 1):\n","    for j in range(i+1, len(columns)):\n","        if corr[columns[i]][columns[j]] > 0.98:\n","            print(columns[i], columns[j], corr[columns[i]][columns[j]])\n","            correlated_vars.append(columns[j])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = df.drop(columns=correlated_vars)"]},{"cell_type":"markdown","metadata":{},"source":["## Splitting training and testing sets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = df.drop(columns=['label'])\n","feature_list = list(X.columns)\n","X = np.array(X)\n","y = df['label']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Training set:\", len(X_train))\n","print(\"Testing set:\", len(X_test))"]},{"cell_type":"markdown","metadata":{},"source":["## Scaling\n","Scaling all features using StandardScaler."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scaler = StandardScaler().fit(X_train)\n","X_train = scaler.transform(X_train)\n","X_test = scaler.transform(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["# Model training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["models = {}\n","models['Decision Tree Classifier'] = DecisionTreeClassifier()\n","models['Random Forest Classifier'] = RandomForestClassifier()\n","models['Gaussian Naive Bayes'] = GaussianNB()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_score, accuracy, precision, recall, training_time, y_pred = {}, {}, {}, {}, {}, {}\n","for key in models.keys():\n","    start_time = time.time()\n","    models[key].fit(X_train, y_train)\n","    training_time[key] = time.time() - start_time\n","    \n","    y_pred[key] = models[key].predict(X_test)\n","    \n","    train_score[key] = models[key].score(X_train, y_train)\n","    accuracy[key] = models[key].score(X_test, y_test)\n","    precision[key] = precision_score(y_test, y_pred[key])\n","    recall[key] = recall_score(y_test, y_pred[key])"]},{"cell_type":"markdown","metadata":{},"source":["Try Feature selection using Recursive Feature Elimination."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rfc_rfe = 'Random Forest Classifier + Recursive Feature Elimination'\n","models[rfc_rfe] = RandomForestClassifier()\n","rfe = RFE(models[rfc_rfe])\n","start_time = time.time()\n","rfe.fit(X_train, y_train)\n","training_time[rfc_rfe] = time.time() - start_time\n","\n","X_train_rfe = rfe.transform(X_train)\n","X_test_rfe = rfe.transform(X_test)\n","\n","start_time = time.time()\n","models[rfc_rfe].fit(X_train_rfe, y_train)\n","training_time[rfc_rfe] = training_time[rfc_rfe] + (time.time() - start_time)\n","    \n","y_pred[key] = models[rfc_rfe].predict(X_test_rfe)\n","    \n","train_score[rfc_rfe] = models[rfc_rfe].score(X_train_rfe, y_train)\n","accuracy[rfc_rfe] = models[rfc_rfe].score(X_test_rfe, y_test)\n","precision[rfc_rfe] = precision_score(y_test, y_pred[key])\n","recall[rfc_rfe] = recall_score(y_test, y_pred[key])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Old number of features:\", X.shape[1])\n","print(\"New number of features:\", len(rfe.estimator_.feature_importances_))"]},{"cell_type":"markdown","metadata":{},"source":["## Models comparison"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_models = pd.DataFrame(index=models.keys(), columns=['Training score', 'Accuracy', 'Precision', 'Recall', 'Training time'])\n","df_models['Training score'] = train_score.values()\n","df_models['Accuracy'] = accuracy.values()\n","df_models['Precision'] = precision.values()\n","df_models['Recall'] = recall.values()\n","df_models['Training time'] = training_time.values()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_models"]},{"cell_type":"markdown","metadata":{},"source":["Because Random Forest Classifier is the best model so far. We will choose this model for the Intrusion Detection System.\n","The following are more details about this model."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["display = RocCurveDisplay.from_estimator(models['Random Forest Classifier'], X_test, y_test)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["display = PrecisionRecallDisplay.from_predictions(y_test, y_pred['Random Forest Classifier'])"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["cm = confusion_matrix(y_test, y_pred['Random Forest Classifier'], labels=models['Random Forest Classifier'].classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=models['Random Forest Classifier'].classes_)\n","disp.plot(cmap='Blues')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":5}
